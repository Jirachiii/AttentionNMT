{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (22.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-22.3.1-py3-none-any.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 1.3 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.1.2\n",
      "    Uninstalling pip-22.1.2:\n",
      "      Successfully uninstalled pip-22.1.2\n",
      "Successfully installed pip-22.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts pip.exe, pip3.10.exe, pip3.9.exe and pip3.exe are installed in 'C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: OpenNMT-py in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (3.0.0)\n",
      "Requirement already satisfied: sacrebleu in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from OpenNMT-py) (2.3.1)\n",
      "Requirement already satisfied: pyonmttok<2,>=1.23 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from OpenNMT-py) (1.31.0)\n",
      "Requirement already satisfied: flask in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from OpenNMT-py) (2.1.1)\n",
      "Requirement already satisfied: configargparse in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from OpenNMT-py) (1.5.3)\n",
      "Requirement already satisfied: tensorboard>=2.3 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from OpenNMT-py) (2.8.0)\n",
      "Requirement already satisfied: waitress in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from OpenNMT-py) (2.1.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from OpenNMT-py) (6.0)\n",
      "Requirement already satisfied: torch>=1.12.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from OpenNMT-py) (1.12.1+cu116)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from tensorboard>=2.3->OpenNMT-py) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from tensorboard>=2.3->OpenNMT-py) (3.3.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from tensorboard>=2.3->OpenNMT-py) (2.1.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from tensorboard>=2.3->OpenNMT-py) (58.1.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from tensorboard>=2.3->OpenNMT-py) (0.4.6)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from tensorboard>=2.3->OpenNMT-py) (1.44.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from tensorboard>=2.3->OpenNMT-py) (2.27.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from tensorboard>=2.3->OpenNMT-py) (1.0.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from tensorboard>=2.3->OpenNMT-py) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from tensorboard>=2.3->OpenNMT-py) (2.6.5)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from tensorboard>=2.3->OpenNMT-py) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from tensorboard>=2.3->OpenNMT-py) (1.22.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from tensorboard>=2.3->OpenNMT-py) (0.6.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torch>=1.12.1->OpenNMT-py) (4.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from flask->OpenNMT-py) (4.11.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from flask->OpenNMT-py) (3.1.1)\n",
      "Requirement already satisfied: click>=8.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from flask->OpenNMT-py) (8.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from flask->OpenNMT-py) (2.1.2)\n",
      "Requirement already satisfied: lxml in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sacrebleu->OpenNMT-py) (4.9.1)\n",
      "Requirement already satisfied: regex in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sacrebleu->OpenNMT-py) (2022.4.24)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sacrebleu->OpenNMT-py) (0.9.0)\n",
      "Requirement already satisfied: portalocker in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sacrebleu->OpenNMT-py) (2.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sacrebleu->OpenNMT-py) (0.4.4)\n",
      "Requirement already satisfied: six in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from absl-py>=0.4->tensorboard>=2.3->OpenNMT-py) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (5.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.3->OpenNMT-py) (1.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from importlib-metadata>=3.6.0->flask->OpenNMT-py) (3.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from Jinja2>=3.0->flask->OpenNMT-py) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (2021.10.8)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from portalocker->sacrebleu->OpenNMT-py) (304)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.3->OpenNMT-py) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install OpenNMT-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 22 22:26:17 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 522.06       Driver Version: 522.06       CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   49C    P8    N/A /  N/A |      0MiB /  3072MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     13364      C   ...\\app-1.0.9007\\Discord.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-22 22:39:54,796 INFO] Missing transforms field for corpus_1 data, set to default: [].\n",
      "[2022-11-22 22:39:54,796 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
      "[2022-11-22 22:39:54,796 INFO] Missing transforms field for valid data, set to default: [].\n",
      "[2022-11-22 22:39:54,796 INFO] Parsed 2 corpora from -data.\n",
      "[2022-11-22 22:39:54,796 INFO] Get special vocabs from Transforms: {'src': set(), 'tgt': set()}.\n",
      "[2022-11-22 22:39:55,011 INFO] Building model...\n",
      "[2022-11-22 22:39:56,365 INFO] NMTModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(25968, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (transformer): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(32768, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "    (transformer_layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerDecoderLayer(\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerDecoderLayer(\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerDecoderLayer(\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerDecoderLayer(\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (generator): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=32768, bias=True)\n",
      "    (1): Cast()\n",
      "    (2): LogSoftmax(dim=-1)\n",
      "  )\n",
      ")\n",
      "[2022-11-22 22:39:56,369 INFO] encoder: 32198656\n",
      "[2022-11-22 22:39:56,369 INFO] decoder: 52496384\n",
      "[2022-11-22 22:39:56,369 INFO] * number of parameters: 84695040\n",
      "[2022-11-22 22:39:56,369 INFO]  * src vocab size = 25968\n",
      "[2022-11-22 22:39:56,369 INFO]  * tgt vocab size = 32768\n",
      "[2022-11-22 22:39:56,372 INFO] Starting training on GPU: [0]\n",
      "[2022-11-22 22:39:56,372 INFO] Start training loop and validate every 1000 steps...\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\onmt\\bin\\train.py\", line 69, in <module>\n",
      "    main()\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\onmt\\bin\\train.py\", line 65, in main\n",
      "    train(opt)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\onmt\\bin\\train.py\", line 50, in train\n",
      "    train_process(opt, device_id=0)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\onmt\\train_single.py\", line 167, in main\n",
      "    trainer.train(\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\onmt\\trainer.py\", line 238, in train\n",
      "    for i, batches in enumerate(\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\onmt\\trainer.py\", line 185, in _accum_batches\n",
      "    for batch in iterator:\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\onmt\\inputters\\inputter.py\", line 28, in __iter__\n",
      "    for tensor_batch in self.iterable:\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\utils\\data\\dataloader.py\", line 444, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\utils\\data\\dataloader.py\", line 390, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1077, in __init__\n",
      "    w.start()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py\", line 121, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py\", line 224, in _Popen\n",
      "    return _default_context.get_context().Process._Popen(process_obj)\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py\", line 327, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py\", line 93, in __init__\n",
      "    reduction.dump(process_obj, to_child)\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py\", line 60, in dump\n",
      "    ForkingPickler(file, protocol).dump(obj)\n",
      "TypeError: cannot pickle 'pyonmttok._ext.Vocab' object\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "EOFError: Ran out of input\n"
     ]
    }
   ],
   "source": [
    "!python3 C:/Users/Admin/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/onmt/bin/train.py -config transformer.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ytrang')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4fef6e4efb2d97227a53c70c433a4c289e89722e2806c39fb9713a5823fc0aac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
